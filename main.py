import os
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write
from dotenv import load_dotenv
import assemblyai as aai
import google.generativeai as genai
import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
import time

# Carregar variÃ¡veis de ambiente
load_dotenv()

# Chaves das APIs
aai.settings.api_key = os.getenv("ASSEMBLYAI_API_KEY")
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

def gravar_audio_dinamico(fs=16000, output="audio.wav", threshold=100, max_silence_duration=3):
    print("ğŸ™ï¸ Aguarde... escutando para iniciar gravaÃ§Ã£o")

    buffer = []
    silence_start = None
    gravando = False
    bloco_tamanho = int(0.5 * fs)  # 0.5 segundo de Ã¡udio por bloco

    with sd.InputStream(samplerate=fs, channels=1) as stream:
        while True:
            bloco, _ = stream.read(bloco_tamanho)
            bloco = bloco.flatten()
            energia = np.sqrt(np.mean(bloco**2)) * 1000

            if energia > threshold:
                if not gravando:
                    print("ğŸ¤ Iniciando gravaÃ§Ã£o...")
                    gravando = True
                buffer.append(bloco)
                silence_start = None  # resetar contador de silÃªncio
            else:
                if gravando:
                    if silence_start is None:
                        silence_start = time.time()
                    elif time.time() - silence_start >= max_silence_duration:
                        print("ğŸ›‘ SilÃªncio detectado. Encerrando gravaÃ§Ã£o.")
                        break

    # Salvar Ã¡udio
    audio_final = np.concatenate(buffer)
    audio_final = np.int16(audio_final * 32767)
    write(output, fs, audio_final)
    print(f"âœ… Ãudio gravado como {output}")

# Transcreve o Ã¡udio usando a AssemblyAI com idioma portuguÃªs
def transcrever_audio_assemblyai(caminho_audio="audio.wav"):
    print("â³ Transcrevendo com AssemblyAI...")
    config = aai.TranscriptionConfig(
        language_code="pt",
        speech_model=aai.SpeechModel.best
    )
    transcriber = aai.Transcriber(config=config)
    transcript = transcriber.transcribe(caminho_audio)

    if transcript.status == "error":
        raise RuntimeError(f"âŒ Erro na transcriÃ§Ã£o: {transcript.error}")

    texto = transcript.text
    print("ğŸ“ Texto transcrito:", texto)
    
    return texto

# Usa o Gemini para gerar sugestÃ£o com base no texto transcrito
def obter_sugestao_com_gemini(texto_transcrito):
    model = genai.GenerativeModel("gemini-1.5-flash")
    prompt = f"Eu acabei de dizer: '{texto_transcrito}'. Sugira de forma curta como posso responder ou continuar falando com o cliente."

    resposta = model.generate_content(prompt)
    sugestao = resposta.text.strip()
    print("ğŸ’¡ SugestÃ£o de continuaÃ§Ã£o:", sugestao)
    return sugestao

gravar_audio_dinamico()

